# Parallel Processing Implementation

## Progress Summary

Legend:
üîÑ = In Progress
‚ö†Ô∏è = Blocked/Has Issues
‚úÖ = Completed

### Current Status:
Planning phase - Implementing parallel processing architecture with static batch sizing

### Next Implementation Steps:
1. Implement parallel process pool
2. Add worker thread support to Sharp sidecar
3. Update metrics collection
4. Integrate parallel processing with existing commands

## Implementation Plan

### 1. Parallel Process Pool Implementation

[ ] Create new parallel process pool structure
   Short description: Implement the core parallel processing pool structure
   Prerequisites: None
   Files to modify: src-tauri/src/processing/pool/process_pool.rs
   External dependencies: None
   Code to add:
   ```rust
   pub struct ParallelProcessPool {
       semaphore: Arc<Semaphore>,
       app: tauri::AppHandle,
       max_size: usize,
       active_count: Arc<Mutex<usize>>,
       metrics: Arc<Mutex<ProcessPoolMetrics>>,
       task_queue: Arc<Mutex<VecDeque<QueuedTask>>>,
       batch_size: usize,  // Static 75 images per batch
   }

   impl ParallelProcessPool {
       pub fn new(app: tauri::AppHandle) -> Self {
           let size = Self::calculate_optimal_processes();
           Self::new_with_size(app, size)
       }

       fn calculate_optimal_processes() -> usize {
           let cpu_count = num_cpus::get();
           ((cpu_count * 3) / 4).max(2).min(24)
       }
   }
   ```

[ ] Implement batch processing logic
   Short description: Add methods for parallel batch processing
   Prerequisites: Parallel process pool structure
   Files to modify: src-tauri/src/processing/pool/process_pool.rs
   Code to add:
   ```rust
   impl ParallelProcessPool {
       pub async fn process_batch(&self, tasks: Vec<ImageTask>) 
           -> OptimizerResult<Vec<OptimizationResult>> {
           let batches = self.create_batches(tasks);
           let mut handles = Vec::new();
           
           for batch in batches {
               let handle = self.process_single_batch(batch).await?;
               handles.push(handle);
           }
           
           self.collect_results(handles).await
       }

       fn create_batches(&self, tasks: Vec<ImageTask>) -> Vec<Vec<ImageTask>> {
           tasks.chunks(75).map(|chunk| chunk.to_vec()).collect()
       }
   }
   ```

### 2. Sharp Sidecar Worker Implementation

[ ] Add worker thread support to Sharp sidecar
   Short description: Implement worker thread pool in Node.js sidecar
   Prerequisites: None
   Files to modify: sharp-sidecar/index.js
   External dependencies: worker_threads (Node.js built-in)
   Code to add:
   ```javascript
   const { Worker, isMainThread, parentPort } = require('worker_threads');
   const sharp = require('sharp');
   const os = require('os');

   class SharpWorkerPool {
       constructor() {
           this.maxWorkers = os.cpus().length;
           this.workers = new Map();
       }

       async processImage(task) {
           // Worker implementation
       }
   }
   ```

[ ] Implement parallel image processing
   Short description: Add parallel processing support to optimize-batch command
   Prerequisites: Worker thread support
   Files to modify: sharp-sidecar/index.js
   Code to add:
   ```javascript
   async function optimizeBatch(batchJson) {
       const batch = JSON.parse(batchJson);
       const workerPool = new SharpWorkerPool();
       
       const results = await Promise.all(
           batch.map(task => workerPool.processImage(task))
       );
       
       console.log(JSON.stringify(results));
       return results;
   }
   ```

### 3. Metrics Implementation

[ ] Update metrics structure
   Short description: Add basic parallel processing metrics
   Prerequisites: None
   Files to modify: src-tauri/src/benchmarking/metrics.rs
   Code to add:
   ```rust
   pub struct ParallelProcessingMetrics {
       pub total_batches: usize,
       pub concurrent_batches: usize,
       pub batch_processing_times: Vec<Duration>,
       pub total_processed: usize,
   }

   impl ParallelProcessingMetrics {
       pub fn record_batch_completion(&mut self, duration: Duration, size: usize) {
           self.total_batches += 1;
           self.batch_processing_times.push(duration);
           self.total_processed += size;
       }
   }
   ```

[ ] Integrate metrics collection
   Short description: Add metrics collection to parallel processing
   Prerequisites: Updated metrics structure
   Files to modify: 
   - src-tauri/src/processing/pool/process_pool.rs
   - src-tauri/src/benchmarking/reporter.rs
   Code to add/change: Add metrics collection points in process_batch method

### 4. Integration and Testing

[ ] Update image commands
   Short description: Integrate parallel processing with existing commands
   Prerequisites: All above implementations
   Files to modify: src-tauri/src/commands/image.rs
   Code changes: Update optimize_images command to use parallel processing

[ ] Add basic error handling
   Short description: Implement error handling for parallel processing
   Prerequisites: Command integration
   Files to modify: src-tauri/src/processing/pool/process_pool.rs
   Code to add: Error handling for batch processing failures

## Implementation Notes
- Keep batch size static at 75 images
- Focus on parallel processing implementation first
- Keep metrics simple and focused on essential measurements
- Maintain existing API contracts
- Test thoroughly with varying batch sizes

## Completed Tasks

## Findings

### Known Issues:
- None yet

### Technical Insights:
- Static batch size of 75 images provides a good balance
- Worker thread implementation in Sharp sidecar crucial for performance
- Simple metrics provide essential insights without overhead